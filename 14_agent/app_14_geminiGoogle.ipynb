{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(verbose=True)\n",
    "key = os.getenv('OPENAI_API_KEY')\n",
    "google_key = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    api_key=google_key, \n",
    "    model=\"gemini-1.5-pro-latest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm.stream(\"랭체인에 대해서 간략히 설명해 줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랭체인(LangChain)은 대규모 언어 모델(LLM)을 사용하여 애플리케이션을 개발하기 위한 프레임워크입니다.  복잡한 작업을 수행하기 위해 여러 LLM 호출을 연결하는 것을 단순화하고, LLM을 다른 소스의 데이터와 결합하는 기능을 제공합니다.\n",
      "\n",
      "핵심 아이디어는 LLM의 기능을 확장하여 다음과 같은 작업을 가능하게 하는 것입니다.\n",
      "\n",
      "* **긴 문서 요약:** LLM의 입력 길이 제한을 극복하여 긴 문서를 효과적으로 요약합니다.\n",
      "* **챗봇:**  더 풍부하고 매력적인 대화를 생성하기 위해 외부 데이터 소스 및 도구와 상호 작용하는 챗봇을 구축합니다.\n",
      "* **질의응답:** 특정 문서 또는 데이터 세트에 대한 질문에 답변할 수 있는 시스템을 만듭니다.\n",
      "* **코드 분석:** 코드를 분석하고, 설명을 생성하고, 오류를 찾을 수 있습니다.\n",
      "\n",
      "랭체인은 다음과 같은 주요 구성 요소를 제공합니다.\n",
      "\n",
      "* **모델:** OpenAI, Hugging Face 등 다양한 LLM 제공업체와 통합됩니다.\n",
      "* **프롬프트:** LLM에 대한 입력을 관리하고 최적화하는 데 도움이 되는 템플릿과 도구를 제공합니다.\n",
      "* **메모리:** 대화나 일련의 상호 작용에서 상태를 유지합니다.\n",
      "* **인덱스:** 외부 데이터를 LLM에 사용할 수 있는 형식으로 변환합니다.\n",
      "* **체인:** 여러 LLM 호출이나 다른 작업을 순차적으로 연결합니다.\n",
      "* **콜백:** 실행 중인 작업을 모니터링하고 로깅합니다.\n",
      "* **에이전트:** LLM이 도구를 사용하고 작업을 수행할 수 있도록 합니다.\n",
      "\n",
      "\n",
      "간단히 말해서, 랭체인은 LLM을 더욱 강력하고 유용하게 만들어주는 도구 상자라고 생각하면 됩니다.  LLM의 한계를 극복하고 실제 애플리케이션에 적용하기 위한 빌딩 블록을 제공합니다."
     ]
    }
   ],
   "source": [
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_response\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예."
     ]
    }
   ],
   "source": [
    "# ChatGoogleGenerativeAI 언어 모델을 초기화합니다.\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    api_key=google_key, \n",
    "    model=\"gemini-1.5-pro-latest\"\n",
    ")\n",
    "\n",
    "# 프롬프트를 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"예/아니오 질문에 대답하세요. {question}는 과일입니까?\"\n",
    ")\n",
    "\n",
    "# 체인을 생성합니다.\n",
    "chain = prompt | model\n",
    "\n",
    "# 결과를 출력합니다.\n",
    "stream_response(chain.stream({\"question\": \"사과\"}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
